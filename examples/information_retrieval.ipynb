{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd35341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f3731-9c4e-41d5-9223-9c399d9bb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67126b-8674-4767-9e3f-38fe05dca625",
   "metadata": {},
   "source": [
    "# Import libs and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343787b-0e9f-42d4-acea-fa1fcd6689cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from recallmate.columns import Columns\n",
    "from recallmate.data.memory import ItemMemory, UserMemory\n",
    "from recallmate.tasks.information_retrieval import RetrievalRecommenderSimple\n",
    "from recallmate.llm import load_model_openai\n",
    "from recallmate.agents.tools import create_retrieval_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a32df-3f44-4660-8f75-d4525e4c9927",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4091b-3a12-4b19-90e7-1619baf07254",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!wget -q https://files.grouplens.org/datasets/movielens/ml-100k.zip -O ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "!rm ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48852a-f3e6-4b80-a4ef-d8ffb911ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_DATA = Path(\"./ml-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f55c41-ffa4-4044-9464-69b8f3f272e3",
   "metadata": {},
   "source": [
    "Interaction data, user and product information must contain mandatory attributes.\n",
    "\n",
    "For interactions: \n",
    "    \n",
    "    - \"user_id\": Columns.User\n",
    "    - \"item_id\": Columns.Item\n",
    "\n",
    "For user informations: \n",
    "    \n",
    "    - \"user_id\": Columns.User\n",
    "\n",
    "For item informations: \n",
    "    \n",
    "    - \"item_id\": Columns.Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c4ed2-8d50-4e94-9633-4b1ee028c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_cols = [Columns.User, Columns.Item, Columns.Weight, Columns.Datetime]\n",
    "df_interactions = pd.read_csv(BASE_PATH_DATA / \"ua.base\", sep='\\t', names=inter_cols, encoding='latin-1')\n",
    "df_interactions.sort_values([Columns.User, Columns.Datetime], inplace=True, ignore_index=True)\n",
    "df_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed47d16-d919-456a-a4f6-33c0ffe2d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cols =  [Columns.User, 'age', 'sex', 'occupation', 'zip_code']\n",
    "df_users = pd.read_csv(BASE_PATH_DATA / \"u.user\", sep='|', names=u_cols, encoding='latin-1')\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2cc36-e13f-4fca-955d-c811071bb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(movie_title) -> str:\n",
    "    match = re.search(r'\\((\\d{4})\\)', movie_title)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "    else:\n",
    "        year = -1\n",
    "    return year\n",
    "\n",
    "\n",
    "def extract_title(movie_title) -> str:\n",
    "    title = \"\"\n",
    "    match = re.search(r'^(.*?)\\s*\\(\\d{4}\\)', movie_title)\n",
    "    if match:\n",
    "        title = match.group(1)\n",
    "    return title.strip()\n",
    "    \n",
    "\n",
    "# Load movie genres\n",
    "genre_cols = [\"genre_name\", \"genre_code\"]\n",
    "df_genres = pd.read_csv(BASE_PATH_DATA / \"u.genre\", sep=\"|\", names=genre_cols, encoding=\"latin-1\")\n",
    "unique_genres = df_genres[\"genre_name\"].tolist()\n",
    "\n",
    "# Load movie info\n",
    "i_cols =  [Columns.Item, \"title\", \"release_date\", \"\", \"link\"] + unique_genres\n",
    "df_items = pd.read_csv(BASE_PATH_DATA / \"u.item\", sep=\"|\", names=i_cols, encoding=\"latin-1\")\n",
    "df_items.drop(columns=\"\", inplace=True)\n",
    "\n",
    "# Transform genre from One-Hot to string\n",
    "all_movie_genres = []\n",
    "for idx in range(len(df_items)):\n",
    "    row = df_items.iloc[idx]\n",
    "    movie_genres = []\n",
    "    for g in unique_genres:\n",
    "        if row[g]:\n",
    "            movie_genres.append(g)\n",
    "\n",
    "    all_movie_genres.append(\", \".join(movie_genres))\n",
    "    \n",
    "df_items[\"genres\"] = all_movie_genres\n",
    "\n",
    "# Remove year from title and get year as separeting columns\n",
    "df_items.loc[:, \"year\"] = df_items[\"title\"].map(extract_year)\n",
    "df_items.loc[:, \"title\"] = df_items[\"title\"].map(extract_title)\n",
    "\n",
    "df_items[\"year\"] = df_items[\"year\"].astype(int)\n",
    "\n",
    "df_items.drop(columns=[\"release_date\", \"link\"] + unique_genres, inplace=True)\n",
    "\n",
    "df_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf39f1-61d0-4c10-97f1-5eef220c6ec6",
   "metadata": {},
   "source": [
    "# Create `ItemMemory`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ab07c-4a21-405b-bb35-db02471e0385",
   "metadata": {},
   "source": [
    "Since the data can be varied and not all attributes of users and items can be used, we leave the option to create an input prompt and a function to process it on the user side.\n",
    "\n",
    "However, the function and prompt may not be implemented, in this case they will be created on the module side with all attributes except for the unique identifiers:\n",
    "\n",
    "```python\n",
    "item_memory = ItemMemory(data=df_items)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c97e38-4039-4123-8966-3f1dee4e20e4",
   "metadata": {},
   "source": [
    "Function for translating attributes into text data:\n",
    "\n",
    "Signature this functions must be: \n",
    "```python\n",
    "def create_prompt(prompt: PromptTemplate, data: tp.Union[tp.Dict, pd.Series]) -> str:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6838091-921a-49d4-b495-c958345a09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(prompt: PromptTemplate, data: pd.Series) -> str:\n",
    "    prompt_init = prompt.format(\n",
    "        title=data[\"title\"],\n",
    "        genres=data[\"genres\"],\n",
    "        year=data[\"year\"]\n",
    "    )\n",
    "    return prompt_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f955e-fcd6-4816-bfc8-3c53a3a294e7",
   "metadata": {},
   "source": [
    "Prompt to initialize item information (must include attributes that are processed in the `create_prompt` function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f25ad-8f48-4410-9eb1-a71bfbd8fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prompt_init = PromptTemplate.from_template(\n",
    "    \"The title is '{title}'; The genres are {genres}; The year is '{year}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44dccb-ae5c-457a-ac5d-3eaef7635092",
   "metadata": {},
   "source": [
    "Creating instance ItemMemory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108d1bd-e586-4aab-9f3a-6aa0c9d65ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#     data (pd.DataFrame): The dataframe containing the item data. \n",
    "#     col_id (str): The column name of the item id. Defaults to \"item_id\".\n",
    "#     prompt_init (PromptTemplate): The promt for initialization.\n",
    "#     create_prompt (Callable): The function for translating information into a string.\n",
    "\n",
    "item_memory = ItemMemory(\n",
    "    data=df_items, \n",
    "    prompt_init=item_prompt_init, \n",
    "    create_prompt=create_prompt\n",
    ")\n",
    "item_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035fd01-8cc2-4831-8116-2edad0ab257d",
   "metadata": {},
   "source": [
    "# Create UserMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479ae53-87c7-42f2-8315-a8052fdab32e",
   "metadata": {},
   "source": [
    "Function for translating attributes into text data:\n",
    "\n",
    "Signature of these functions is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889fda1-9925-4e1a-8eaa-73ad8436da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_short_memory(prompt: PromptTemplate, data: tp.Dict) -> str:\n",
    "    prompt_short_init = prompt.format(**{variable: data[variable] for variable in prompt.input_variables})\n",
    "    return prompt_short_init\n",
    "\n",
    "def create_user_overview_from_features(prompt: PromptTemplate, data: pd.Series) -> str:\n",
    "    user_overview = prompt.format(\n",
    "        sex=\"male\" if data[\"sex\"] == \"M\" else \"female\",\n",
    "        age=data[\"age\"],\n",
    "        occupation=data[\"occupation\"]\n",
    "    )\n",
    "    return user_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8e17f-c535-4250-bd09-1e1cdf1a19ab",
   "metadata": {},
   "source": [
    "Prompt to initialize item information (must include attributes that are processed in the corresponding functions above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b7496-2cd6-4bc3-915a-763b67916cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_init = PromptTemplate.from_template(\n",
    "    \"I am a {sex}, I am {age} years old, my profession is a {occupation}.\"\n",
    ")\n",
    "user_long_memory_prompt_init = PromptTemplate.from_template(\n",
    "    \"I watched and gave a rating above 3.5 (minimum rating 1, maximum - 5) \" \n",
    "    \"to the following films (in historical order): {history}\"\n",
    ")\n",
    "user_short_memory_prompt_init = PromptTemplate.from_template(\n",
    "    \"I enjoy watching movies in the following genres: {genres}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518d1fcc-5b9f-4277-86ce-246b3cc33d65",
   "metadata": {},
   "source": [
    "Creating instance UserMemory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c38546-4d2f-417d-b1cc-f8b277ccb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#     data (pd.DataFrame): The dataframe containing the user data. \n",
    "#     interactions (pd.DataFrame): The dataframe containing the interactions of the users.\n",
    "#     item_memory (ItemMemort): The item memory.\n",
    "#     use_prompt_init (bool): Use information of the user or no. Defults True.\n",
    "#     col_id (str): The column name of the user id. Defaults to \"user_id\".\n",
    "#     prompt_init (PromptTemplate): The prompt template for user's information. Defaults None.\n",
    "#     create_prompt (Callable): Function for creating prompt with user's information.\n",
    "#     user_long_memory_prompt_init (PromptTemplate): The prompt template for the user long memory per item. \n",
    "#         Must includes one variable `history`. Defaults PromptTemplate.from_template(\n",
    "#         \"I interected with contents to the following films (in historical order): {history}\"\n",
    "#     )\n",
    "#     user_short_memory_prompt_init (PromptTemplate): The prompt template for the user short memory. Defaults None.\n",
    "#     short_memory_create_prompt (Callable): Function for creating short-term user's prompt. Defaults None.\n",
    "#     long_memory_n (int): The number of items to keep in the long term memory. Defaults to 20.\n",
    "#     short_memory_n (int): The number of items to keep in the short term memory. Defaults to 5.\n",
    "\n",
    "user_memory = UserMemory(\n",
    "    data=df_users,\n",
    "    interactions=df_interactions,\n",
    "    item_memory=item_memory,\n",
    "    use_prompt_init=True,\n",
    "    prompt_init=user_prompt_init,\n",
    "    create_prompt=create_user_overview_from_features,\n",
    "    user_long_memory_prompt_init=user_long_memory_prompt_init,\n",
    "    user_short_memory_prompt_init=user_short_memory_prompt_init,\n",
    "    short_memory_create_prompt=create_prompt_short_memory,\n",
    "    long_memory_n=10,\n",
    "    short_memory_n=5,\n",
    ")\n",
    "user_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751baf0b-1350-4a71-9382-403ef4797045",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a328f-9342-425a-99cb-823ad90efeda",
   "metadata": {},
   "source": [
    "Load token for model's OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e8b07-a7c6-4416-839a-982d98ab6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../openai.env\")\n",
    "OPEN_AI_API_KEY = os.environ.get(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaaa836-daf3-4cd1-8e12-6e42ab9f0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#     model_name (str): The name of the model to load.\n",
    "#     openai_api_key (str): The API key for accessing the OpenAI service.\n",
    "#     mode (str): Type of the model for loading. Default is `generation`.\n",
    "#     embeddings_model_args (Optional[Dict[str, Any]]): Additional arguments for the embeddings model. Default is None.\n",
    "    \n",
    "# Returns:\n",
    "#     OpenAIEmbeddings: An instance of the OpenAIEmbeddings model loaded with the specified parameters.\n",
    "\n",
    "llm = load_model_openai(\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    openai_api_key=OPEN_AI_API_KEY,\n",
    "    mode=\"embedding\",\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e367543-366d-4567-9b5c-984528d08dd5",
   "metadata": {},
   "source": [
    "# Create Inofrmation Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa2037-baff-430c-b4b5-cb3192002a81",
   "metadata": {},
   "source": [
    "Create an instance of the class for information search, with the help of which we will make recommendations\n",
    "\n",
    "The information search component takes as input the memory about items, encoding llm and other auxiliary parameters.Create an instance of the class for information search, with the help of which we will make recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb71c4b-cdcd-4cd1-94d5-a16ad0e623ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#     item_memory (ItemMemory): Memory of the items.\n",
    "#     embeddings_model (OpenAIEmbeddings | HuggingFaceEmbedding | OpenSourceLLMEmbeddings): Embedding model.\n",
    "#     col_item_id (str): Column name with item id. Default \"item_id\"\n",
    "#     text_splitter_args (TextSplitter): Arguments for splitting text. Default {'chunk_size': 1000, 'chunk_overlap': 0}\n",
    "#     log (bool): Logging running.\n",
    "            \n",
    "retrieval_recommender = RetrievalRecommenderSimple(\n",
    "    item_memory=item_memory,\n",
    "    embeddings_model=llm,\n",
    "    col_item_id=Columns.Item,\n",
    "    text_splitter_args={'chunk_size': 1000, 'chunk_overlap': 0},\n",
    "    log=True,\n",
    ")\n",
    "retrieval_recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77bdfed-645c-40c8-b184-8b02c64c2577",
   "metadata": {},
   "source": [
    "# Recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3001ba-9aec-48d0-8762-ce1aa2d06038",
   "metadata": {},
   "source": [
    "To get the recommendations, you need to call the `run` method from infromation retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb2a0c-0d89-4124-9dd3-4c2776147070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of recommendations we want to get\n",
    "TOP_K = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86022884-9b24-4947-b5cc-71824e4d9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#     user_memory (BaseMemory): The memory of the users.\n",
    "#     instruct (str, optional): Additional instructions for the recommendation process. Defaults to None.\n",
    "#     users_for_recommend (tp.Sequence[tp.Any], optional): Specific users for whom recommendations should be generated. Defaults to None.\n",
    "#     use_user_memory_short (bool): Flag to indicate whether to use short-term memory in the recommendation process. Defaults to True.\n",
    "#     use_user_memory_long (bool): Flag to indicate whether to use long-term memory in the recommendation process. Defaults to True.\n",
    "#     search_type (str): The type of search to be performed. Defaults to \"similarity\".\n",
    "#     search_kwargs (tp.Dict[str, tp.Any]): Keyword arguments for the search process. Defaults to {\"k\": 10}.\n",
    "#     add_rank (bool): Flag to add ranking to the recommendations. Defaults to True.\n",
    "\n",
    "# Returns:\n",
    "#     pd.DataFrame: A DataFrame containing user recommendations with user IDs, item IDs, and ranks (optional).\n",
    "\n",
    "reco_openai = retrieval_recommender.run(\n",
    "    user_memory=user_memory,\n",
    "    users_for_recommend=df_users[Columns.User].unique().tolist()[:10],\n",
    "    use_user_memory_short=False,\n",
    "    use_user_memory_long=True,\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": TOP_K},\n",
    "    add_rank=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e09b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_openai.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928498b1-d936-42d8-a381-61bac5ba5e0c",
   "metadata": {},
   "source": [
    "# Create IR Tool for Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d60ce-6e2a-4e7c-9cde-2d0878265c9a",
   "metadata": {},
   "source": [
    "The agent needs to know what the features do in order to make the correct selections. Therefore, a description must be created for them.\n",
    "\n",
    "Creating description for IR Tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a8bbe-26a0-45da-887a-6ec26367e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_tool = (\n",
    "    \"Search content that is most similar to content from previous interactions with the recommender system.\\n\"\n",
    "    \"If you have any questions about searching related content, you should use this tool!\\n\"\n",
    "    \"Give your answer in the following format:\\n\"\n",
    "    \"```\\n\"\n",
    "    \"Candidate movies to recommend for the user:\\n\"\n",
    "    \"1. Movie ID: {{id}} Title: {{title}}. Release year: {{year}}. Genres: {{genres}}. Overview: {{overview}}\\n\"\n",
    "    \"...\\n\"\n",
    "    \"{{n}}. Movie ID: {{id}} Title: {{title}}. Release year: {{year}}. Genres: {{genres}}. Overview: {{overview}}\\n\"\n",
    "    \"```\\n\"\n",
    "    \"where {{n}} is number of recommended movies for the user, {{id}} is movie ID, {{year}} is release year of movie, \"\n",
    "    \"{{genres}} are movie genres, {{overview}} is movie overview.\\n\"\n",
    "    \"You must strictly follow the given output format and not write anything outside the given format!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267539db-e1d3-4e37-9431-5c614ed51fbb",
   "metadata": {},
   "source": [
    "Creating IR Tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc0878-7f2f-493b-9dd4-dcbcf9ae0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters:\n",
    "#     retrieval (Recommender): The retrieval to use for the retrieval\n",
    "#     name (str): The name for the tool. This will be passed to the language model,\n",
    "#         so should be unique and somewhat descriptive. Default  \"retrieval_recommender\".\n",
    "#     description (str): The description for the tool. This will be passed to the language\n",
    "#         model, so should be descriptive. Default (\n",
    "#            \"Search content that is most similar to content from previous interactions with the recommender system.\\n\"\n",
    "#            \"If you have any questions about searching related content, you should use this tool!\\n\"\n",
    "#        )\n",
    "#     args_schema (BaseModel): The schema of the tool's input arguments. Default RetrieveInput.\n",
    "#     return_direct (bool): Whether to return the result directly or as a callback.\n",
    "#     infer_schema (bool): Whether to infer the schema from the function's signature.\n",
    "\n",
    "# Returns:\n",
    "#     (Tool): Tool class to pass to an agent\n",
    "                                          \n",
    "retrieval_recommender_tool = create_retrieval_tool(\n",
    "    retrieval=retrieval_recommender,\n",
    "    description=description_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6285c-3e45-4b82-8a84-498a2c5af318",
   "metadata": {},
   "source": [
    "# Recommend via IR Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bcfc0-0d34-4f1d-9506-7677e92ae79c",
   "metadata": {},
   "source": [
    "The parameters are the same as for the run method in information retrieval, BUT wrapped in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80df0e-0070-4def-84e8-74410dd8e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_openai_from_tool = retrieval_recommender_tool.invoke(\n",
    "    dict(\n",
    "        user_memory=user_memory,\n",
    "        users_for_recommend=df_users[Columns.User].unique().tolist()[:10],\n",
    "        use_user_memory_short=True,\n",
    "        use_user_memory_long=True,\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": TOP_K},\n",
    "        add_rank=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_openai_from_tool.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b504b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
